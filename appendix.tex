\appendix
\chapter{Appendix}
%\section{Additional Results}
%In this Appendix one can find additional plots of the benchmarks as well as tables with details about the benchmark measurements.
\begin{figure}[!htb]
\centering
\includegraphics[width=0.71\textwidth]{./Bilder/single_plots/edge_vs_cloud_plots/Edge_vs_Cloud_Inference_Preprocessing_CPU.pdf}
\caption[Edge vs. Cloud Inference: $CPU_{preprocessing}$ - lower is better]{Edge vs. Cloud Inference: $CPU_{preprocessing}$ - lower is better - 
All $CPU_{preprocessing}$ usages are around $12.5\%$, cloud inference with cloud preprocessing having tendencies to a slightly lower usage.}
\label{fig:CloudEdgePreproCPU}
\end{figure}

\begin{figure}[!htb]
\centering
\includegraphics[width=0.71\textwidth]{./Bilder/single_plots/edge_vs_cloud_plots/Edge_vs_Cloud_Inference_Inference_Latencies_WITHOUT_NETWORK.pdf}
\caption{Edge vs. Cloud Inference: $Latency_{inference}$ without $Latency_{network}$ - lower is better - The network has little impact on the total inference latency.}
\label{fig:CloudEdgeInfLatWONetwork}
\end{figure}








\begin{figure}[!htb]
\centering
\begin{subfigure}[b]{0.95\textwidth}
   \includegraphics[width=1\linewidth]{./Bilder/single_plots/batch_size_plots/Effects_of_Batch_size_Received_Data.pdf}
   \caption{$Data_{received}$}
   \label{fig:BatchSizeReceivedData} 
\end{subfigure}

\begin{subfigure}[b]{0.95\textwidth}
   \includegraphics[width=1\linewidth]{./Bilder/single_plots/batch_size_plots/Effects_of_Batch_size_Transmitted_Data.pdf}
   \caption{$Data_{transmitted}$}
   \label{fig:BatchSizeTransmittedData}
\end{subfigure}

\caption{Edge vs.  Cloud Inference for larger Batch Sizes:  $Data_{received}$ vs. $Data_{transmitted}$ - lower is better - Increasing batch and image sizes result in more data transmitted and received.}
\end{figure}


\begin{figure}[!htb]
\centering
\begin{subfigure}[b]{0.95\textwidth}
   \includegraphics[width=1\linewidth]{./Bilder/single_plots/batch_size_plots/Effects_of_Batch_size_Inference_server_lat.pdf}
   \caption{$Latency_{server}$}
   \label{fig:BatchSizeServer} 
\end{subfigure}

\begin{subfigure}[b]{0.95\textwidth}
   \includegraphics[width=1\linewidth]{./Bilder/single_plots/batch_size_plots/Effects_of_Batch_size_Inference_network_lat.pdf}
   \caption{$Latency_{network}$}
   \label{fig:BatchSizeNetwork}
\end{subfigure}

\caption{Edge vs.  Cloud Inference for larger Batch Sizes:  $Latency_{server}$ vs. $Latency_{network}$ - lower is better - While server latency increases over rising image and batch sizes, network latency stays nearly constant.}
\end{figure}



%Add not so important result figures here%
%Table with the metrics
%\input{./Bilder/metrics_table.tex}
\begin{sidewaystable}


    \centering
    \caption{InceptionV4 - Averages for all Metrics including standard deviation}
\scalebox{0.345}{
\input{./Bilder/table_inception.tex}}

\label{measurementsInception}
\end{sidewaystable}
\begin{sidewaystable}


    \centering
    \caption{MobileNetV2 - Averages for all Metrics including standard deviation}
\scalebox{0.345}{
\input{./Bilder/table_mobilenet.tex}}

\label{measurementsMobilenet}
\end{sidewaystable}

\lstset{basicstyle=\scriptsize}
\begin{minipage}{\linewidth}
\begin{lstlisting}[caption = $\hat{Y}_{Edge}$ Summary, escapeinside={(*}{*)}, label=lst:edgeModelSummary]
                            OLS Regression Results                            
==============================================================================
Dep. Variable:              (*$Latency_{total}$*)   R-squared:                       0.948
Model:                            OLS   Adj. R-squared:                  0.947
Method:                 Least Squares   F-statistic:                     930.9
Date:                Fri, 08 Mar 2019   Prob (F-statistic):           3.10e-66
Time:                        09:04:09   Log-Likelihood:                -540.54
No. Observations:                 105   AIC:                             1087.
Df Residuals:                     102   BIC:                             1095.
Df Model:                           2                                         
================================================================================
                  coef      std err       t        P>|t|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept      124.1744      4.007     30.991      0.000     116.227     132.122
MobileNetV2    -39.9870      4.466     -8.953      0.000     -48.846     -31.128
InceptionV4    164.1614      4.755     34.527      0.000     154.731     173.592
ImageSize     2.554e-05   7.16e-07     35.665      0.000    2.41e-05     2.7e-05
================================================================================
\end{lstlisting}

\begin{lstlisting}[caption = $\hat{Y}_{Cloud_{EdgePrepro}}$ Summary, escapeinside={(*}{*)}, label=lst:CloudEdgePreproModelSummary]
                            OLS Regression Results                            
==============================================================================
Dep. Variable:              (*$Latency_{total}$*)   R-squared:                       0.964
Model:                            OLS   Adj. R-squared:                  0.964
Method:                 Least Squares   F-statistic:                     1378.
Date:                Fri, 08 Mar 2019   Prob (F-statistic):           1.50e-74
Time:                        09:04:09   Log-Likelihood:                -496.60
No. Observations:                 105   AIC:                             999.2
Df Residuals:                     102   BIC:                             1007.
Df Model:                           2                                         
================================================================================
                  coef      std err       t        P>|t|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept      135.7102      2.736     49.607      0.000     130.284     141.136
MobileNetV2     26.8673      2.906      9.244      0.000      21.102      32.632
InceptionV4    108.8429      3.204     33.967      0.000     102.487     115.199
ImageSize     2.436e-05   5.06e-07     48.147      0.000    2.34e-05    2.54e-05
================================================================================
\end{lstlisting}
\end{minipage}

\begin{minipage}{\linewidth}
\begin{lstlisting}[caption = $\hat{Y}_{Cloud_{CloudPrepro}}$ Summary, escapeinside={(*}{*)}, label=lst:CloudCloudPreproModelSummary]
                            OLS Regression Results                            
==============================================================================
Dep. Variable:              (*$Latency_{total}$*)   R-squared:                       0.897
Model:                            OLS   Adj. R-squared:                  0.895
Method:                 Least Squares   F-statistic:                     446.2
Date:                Fri, 08 Mar 2019   Prob (F-statistic):           3.64e-51
Time:                        09:04:10   Log-Likelihood:                -688.43
No. Observations:                 105   AIC:                             1383.
Df Residuals:                     102   BIC:                             1391.
Df Model:                           2                                         
================================================================================
                  coef      std err       t        P>|t|      [0.025      0.975]
--------------------------------------------------------------------------------
Intercept      158.6698     16.568      9.577      0.000     125.807     191.533
MobileNetV2     22.3658     18.183      1.230      0.222     -13.700      58.431
InceptionV4    136.3039     19.521      6.983      0.000      97.585     175.023
ImageSize      9.35e-05    3.2e-06     29.224      0.000    8.72e-05    9.98e-05
================================================================================
\end{lstlisting}
\end{minipage}