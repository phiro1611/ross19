\vspace*{2cm}

\begin{center}
    \textbf{Abstract}
\end{center}

\vspace*{1cm}


%\noindent When deploying realtime AI applications, a crucial aspect is the decision whether to deploy the underlying deep learning models on edge devices or on a cloud-backend.
%For the deployment of a model various things need to be considered, most importantly accuracy and inference time, but also energy consumption, memory consumption, throughput and retraining
\noindent When deploying real-time AI applications, a crucial aspect is the decision whether to deploy the underlying deep learning models on edge devices or on a cloud-backend.
For the model inference various things need to be considered, amongst other things preprocessing, computational demands,
specialised hardware (GPU, TPU, neuromorphic co-processors, FPGA),
network latencies and energy consumption. Most of these aspects depend on both the model as well as the environment where the model is deployed. 
In order to help with the optimal selection of cloud and edge inference to achieve real-time AI, this thesis proposes a performance model characterising the deployment of a deep learning model and the resulting trade-offs.
Based on this performance model, the most essential trade-offs of the different deployment options get demonstrated by conducting multiple experiments using image classification as a use case. After the evaluation of these experiments, recommendations for the deployment are proposed.





